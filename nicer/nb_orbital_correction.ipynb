{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.io import fits\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_logging(fits_file, initial_message=None):\n",
    "    # Extract the directory and base name from the FITS file path\n",
    "    original_dir = os.path.dirname(os.path.dirname(os.path.dirname(fits_file)))  # Get the ObsID folder\n",
    "    base_name = os.path.basename(fits_file).replace('.evt', '')  # Remove the .evt extension\n",
    "    \n",
    "    # Define the log file path in the ObsID folder\n",
    "    log_file_path = os.path.join(original_dir, f\"{base_name}.log\")\n",
    "    \n",
    "    # Overwrite log file each time and write the initial message if provided\n",
    "    with open(log_file_path, 'w') as log_file:\n",
    "        if initial_message:\n",
    "            log_file.write(f\"{initial_message}\\n\")\n",
    "    \n",
    "    return log_file_path\n",
    "\n",
    "def write_log_message(log_file_path, message):\n",
    "    with open(log_file_path, 'a') as log_file:  # Open in append mode\n",
    "        log_file.write(f\"{message}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_event_files(base_directory):\n",
    "    event_files = []\n",
    "    \n",
    "    # Regular expression to match the pattern ObsID/xti/event_cl/\n",
    "    obsid_pattern = re.compile(r'^\\d{10}/xti/event_cl/$')\n",
    "    \n",
    "    # Regular expressions to match the specific filename patterns\n",
    "    file_pattern = re.compile(r'^ni\\d{10}_0mpu7_cl_(night|day)_barycorr\\.evt$')\n",
    "    \n",
    "    # Walk through the directory tree\n",
    "    for root, dirs, files in os.walk(base_directory):\n",
    "        # Extract relative path from the base directory\n",
    "        rel_path = os.path.relpath(root, base_directory)\n",
    "        \n",
    "        # Check if the relative path matches the pattern\n",
    "        if obsid_pattern.match(rel_path + '/'):\n",
    "            # Collect all files in this directory\n",
    "            for file in files:\n",
    "                # Check if the file matches the required patterns\n",
    "                if file_pattern.match(file):\n",
    "                    full_path = os.path.join(root, file)\n",
    "                    event_files.append(full_path)\n",
    "                # else:\n",
    "                #     print(f\"Ignored file: {file} in directory: {rel_path}\")\n",
    "    \n",
    "    return event_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Orbital parameters provided\n",
    "a_sin_i = 115.531  # Semi-major axis in light-seconds\n",
    "P_orb = 27.6943 * 86400  # Orbital period in seconds\n",
    "e = 0.1029  # Eccentricity\n",
    "omega = np.deg2rad(-74.05)  # Longitude of periastron in radians\n",
    "T_pi2 = 58116.097  # T_pi/2 in seconds "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_fits_info(fits_file, log_file_path):\n",
    "    with fits.open(fits_file) as hdul:\n",
    "        header = hdul[1].header\n",
    "        mjdrefi = header['MJDREFI']\n",
    "        mjdreff = header['MJDREFF']\n",
    "        leap_seconds = header.get('TIMEZERO', 0)  # Default to 0 if LEAPINIT not present\n",
    "        met = hdul[1].data['BARYTIME']  # Assuming MET is stored in the 'TIME' column\n",
    "    write_log_message(log_file_path, f\"Extracted MET and header info from {fits_file}\")\n",
    "    return met, mjdrefi, mjdreff, leap_seconds\n",
    "\n",
    "# Step 2: Convert MET to Modified Julian Date (MJD)\n",
    "def convert_met_to_mjd(met, mjdrefi, mjdreff, leap_seconds, log_file_path):\n",
    "    met_in_days = met / 86400.0\n",
    "    mjd = met_in_days + mjdrefi + mjdreff + (leap_seconds / 86400.0)\n",
    "    write_log_message(log_file_path, f\"Converted MET to MJD: {mjd}\")\n",
    "    return mjd\n",
    "\n",
    "# Step 3: Calculate Mean Anomaly M\n",
    "def calculate_mean_anomaly(mjd, T_pi2, P_orb, log_file_path):\n",
    "    mean_anomaly = 2 * np.pi * ((mjd - T_pi2)) / P_orb + np.pi / 2\n",
    "    write_log_message(log_file_path, f\"Calculated Mean Anomaly: {mean_anomaly}\")\n",
    "    return mean_anomaly\n",
    "\n",
    "# Step 4: Compute Eccentric Anomaly E using Mikkola's cubic approximation variable s\n",
    "def compute_eccentric_anomaly_proxy(mean_anomaly, e, log_file_path):\n",
    "    alpha = (1 - e) / (4 * e + 0.5)\n",
    "    beta = 0.5 * mean_anomaly / (4 * e + 0.5)\n",
    "    z = np.where(\n",
    "        beta >= 0,\n",
    "        np.cbrt((beta + np.sqrt(beta**2 + alpha**3))),\n",
    "        np.cbrt((beta - np.sqrt(beta**2 + alpha**3)))\n",
    "    )\n",
    "    s = z - alpha / z\n",
    "    write_log_message(log_file_path, f\"Computed Eccentric Anomaly Proxy: {s}\")\n",
    "    return s\n",
    "\n",
    "# Step 5: Incorporate error term as done in Mikkola 1987\n",
    "def correct_eccentric_anomaly(mean_anomaly, s, e, log_file_path):\n",
    "    ds = (-0.078 * s**5) / (1 + e)\n",
    "    s_true = s + ds\n",
    "    eccentric_anomaly = mean_anomaly + e * (3 * s_true - 4 * s_true**3)\n",
    "    write_log_message(log_file_path, f\"Corrected Eccentric Anomaly: {eccentric_anomaly}\")\n",
    "    return eccentric_anomaly\n",
    "\n",
    "# Step 6: Calculate Rømer time delay for the binary system\n",
    "def calculate_romer_delay(eccentric_anomaly, e, a_sin_i, omega, log_file_path):\n",
    "    sin_E = np.sin(eccentric_anomaly)\n",
    "    cos_E = np.cos(eccentric_anomaly)\n",
    "    romer_delay = a_sin_i * ((cos_E - e) * np.sin(omega) + np.sqrt(1 - e**2) * sin_E * np.cos(omega))\n",
    "    write_log_message(log_file_path, f\"Calculated Rømer Delay: {romer_delay}\")\n",
    "    return romer_delay\n",
    "\n",
    "# Step 7: Correct Event Timestamp\n",
    "def correct_event_timestamp(met, romer_delay, log_file_path):\n",
    "    corrected_timestamp = met - romer_delay\n",
    "    write_log_message(log_file_path, f\"Corrected Event Timestamp: {corrected_timestamp}\")\n",
    "    return corrected_timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_corrected_fits(original_fits, corrected_timestamps, log_file_path):\n",
    "    # Extract the base name and directory from the original FITS file\n",
    "    base_name = os.path.basename(original_fits)\n",
    "    original_dir = os.path.dirname(original_fits)  # Get the directory of the original file\n",
    "    \n",
    "    # Construct the new filename for the corrected FITS file\n",
    "    new_file = os.path.join(original_dir, base_name.replace('.evt', '_orbit.evt'))\n",
    "\n",
    "    try:\n",
    "        # Modify the 'TIME' column with corrected timestamps\n",
    "        with fits.open(original_fits, mode='readonly') as hdul:\n",
    "            # Ensure the data is mutable\n",
    "            hdul[1].data['TIME'] = corrected_timestamps\n",
    "            \n",
    "            # Write the new FITS file in the same directory\n",
    "            hdul.writeto(new_file, overwrite=True)\n",
    "        \n",
    "        write_log_message(log_file_path, f\"Corrected FITS file saved as {new_file}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        write_log_message(log_file_path, f\"Failed to write corrected FITS file {new_file}: {str(e)}\")\n",
    "        print(f\"Error saving corrected FITS file: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(base_directory, T_pi2, P_orb, e, a_sin_i, omega):\n",
    "    event_files = find_event_files(base_directory)\n",
    "    for fits_file in event_files:\n",
    "        print(fits_file)\n",
    "        log_file_path = setup_logging(fits_file)  # Setup logging and get log file path\n",
    "        write_log_message(log_file_path, f\"Processing file: {fits_file}\")\n",
    "\n",
    "        try:\n",
    "            # Step 1: Extract info from the FITS file\n",
    "            met, mjdrefi, mjdreff, leap_seconds = extract_fits_info(fits_file,log_file_path)\n",
    "            write_log_message(log_file_path, f\"Extracted MET and header info from {fits_file}\")\n",
    "\n",
    "            # Step 2: Convert MET to MJD\n",
    "            mjd = convert_met_to_mjd(met, mjdrefi, mjdreff, leap_seconds,log_file_path)\n",
    "            write_log_message(log_file_path, f\"Converted MET to MJD for {fits_file}\")\n",
    "\n",
    "            # Step 3: Calculate Mean Anomaly\n",
    "            mean_anomaly = calculate_mean_anomaly(mjd, T_pi2, P_orb,log_file_path)\n",
    "            write_log_message(log_file_path, f\"Calculated Mean Anomaly for {fits_file}\")\n",
    "\n",
    "            # Step 4: Compute Eccentric Anomaly\n",
    "            s = compute_eccentric_anomaly_proxy(mean_anomaly, e,log_file_path)\n",
    "            write_log_message(log_file_path, f\"Computed Eccentric Anomaly Proxy for {fits_file}\")\n",
    "\n",
    "            # Step 5: Correct Eccentric Anomaly\n",
    "            corrected_eccentric_anomaly = correct_eccentric_anomaly(mean_anomaly, s, e,log_file_path)\n",
    "            write_log_message(log_file_path, f\"Corrected Eccentric Anomaly for {fits_file}\")\n",
    "\n",
    "            # Step 6: Calculate Rømer delay\n",
    "            romer_delay = calculate_romer_delay(corrected_eccentric_anomaly, e, a_sin_i, omega,log_file_path)\n",
    "            write_log_message(log_file_path, f\"Calculated Rømer delay for {fits_file}\")\n",
    "\n",
    "            # Step 7: Correct Event Timestamps\n",
    "            corrected_timestamps = correct_event_timestamp(met, romer_delay,log_file_path)\n",
    "            write_log_message(log_file_path, f\"Corrected event timestamps for {fits_file}\")\n",
    "\n",
    "            # Write the corrected FITS file\n",
    "            write_corrected_fits(fits_file, corrected_timestamps, log_file_path)  # Pass log_file_path here\n",
    "            write_log_message(log_file_path, f\"Successfully processed {fits_file}\")\n",
    "\n",
    "            print('successful for: ',fits_file)\n",
    "            # plt.plot(mjd,met-corrected_timestamps)\n",
    "            # plt.show()\n",
    "\n",
    "        except Exception as e:\n",
    "            write_log_message(log_file_path, f\"Error processing {fits_file}: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./experimenting_orbital_correction/6050390261/xti/event_cl/ni6050390261_0mpu7_cl_night_barycorr.evt\n",
      "successful for:  ./experimenting_orbital_correction/6050390261/xti/event_cl/ni6050390261_0mpu7_cl_night_barycorr.evt\n",
      "./experimenting_orbital_correction/6050390261/xti/event_cl/ni6050390261_0mpu7_cl_day_barycorr.evt\n",
      "successful for:  ./experimenting_orbital_correction/6050390261/xti/event_cl/ni6050390261_0mpu7_cl_day_barycorr.evt\n",
      "./experimenting_orbital_correction/6050390204/xti/event_cl/ni6050390204_0mpu7_cl_night_barycorr.evt\n",
      "successful for:  ./experimenting_orbital_correction/6050390204/xti/event_cl/ni6050390204_0mpu7_cl_night_barycorr.evt\n",
      "./experimenting_orbital_correction/6050390227/xti/event_cl/ni6050390227_0mpu7_cl_night_barycorr.evt\n",
      "successful for:  ./experimenting_orbital_correction/6050390227/xti/event_cl/ni6050390227_0mpu7_cl_night_barycorr.evt\n",
      "./experimenting_orbital_correction/6050390244/xti/event_cl/ni6050390244_0mpu7_cl_night_barycorr.evt\n",
      "successful for:  ./experimenting_orbital_correction/6050390244/xti/event_cl/ni6050390244_0mpu7_cl_night_barycorr.evt\n",
      "./experimenting_orbital_correction/6050390284/xti/event_cl/ni6050390284_0mpu7_cl_night_barycorr.evt\n",
      "successful for:  ./experimenting_orbital_correction/6050390284/xti/event_cl/ni6050390284_0mpu7_cl_night_barycorr.evt\n",
      "./experimenting_orbital_correction/6050390284/xti/event_cl/ni6050390284_0mpu7_cl_day_barycorr.evt\n",
      "successful for:  ./experimenting_orbital_correction/6050390284/xti/event_cl/ni6050390284_0mpu7_cl_day_barycorr.evt\n",
      "./experimenting_orbital_correction/6050390216/xti/event_cl/ni6050390216_0mpu7_cl_day_barycorr.evt\n",
      "successful for:  ./experimenting_orbital_correction/6050390216/xti/event_cl/ni6050390216_0mpu7_cl_day_barycorr.evt\n",
      "./experimenting_orbital_correction/6050390216/xti/event_cl/ni6050390216_0mpu7_cl_night_barycorr.evt\n",
      "successful for:  ./experimenting_orbital_correction/6050390216/xti/event_cl/ni6050390216_0mpu7_cl_night_barycorr.evt\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "base_directory = './experimenting_orbital_correction'  # Change to your base directory\n",
    "main(base_directory, T_pi2, P_orb, e, a_sin_i, omega)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #***********DEBUGGING READING FILES************#\n",
    "# base_directory = './'\n",
    "# event_files = find_event_files(base_directory)\n",
    "# print(\"Found event files:\")\n",
    "# for ef in event_files:\n",
    "#     print(ef)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #********DEBUGGING MJD TIME **********##\n",
    "# hdu=fits.open(fits_file)\n",
    "# hdu[1].data['TIME']+hdu[1].header['MJDREFI']+hdu[1].header['MJDREFF']+hdu[1].header['LEAPINIT']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "heasoftenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
