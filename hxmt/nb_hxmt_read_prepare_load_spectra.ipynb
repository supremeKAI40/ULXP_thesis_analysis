{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "481e6069",
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from collections import defaultdict\n",
    "from astropy.io import fits\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "38adb1f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # --- CONFIGURATION ---\n",
    "# base_dir = \"/home/supremekai/thesis/J0243_6p6124/hxmt/hxmt_me_l3_products_pipeline\"  # Set your base directory\n",
    "# xcm_output_dir = \"/home/supremekai/thesis/J0243_6p6124/hxmt/hxmt_spec_results\"  # Where all .xcm files and log go\n",
    "# os.makedirs(xcm_output_dir, exist_ok=True)\n",
    "\n",
    "# log_path = os.path.join(xcm_output_dir, \"xcm_generation.log\")\n",
    "# log_entries = []\n",
    "\n",
    "# # --- DATA COLLECTION ---\n",
    "# exp_dict = defaultdict(lambda: {'LE': {}, 'ME': {}, 'HE': {}})\n",
    "\n",
    "# for root, dirs, files in os.walk(base_dir):\n",
    "#     if \"pipeline_output\" in root:\n",
    "#         for fname in files:\n",
    "#             match = re.match(r\"(.*?)_(LE|ME|HE)_spec(?:_g0)?\\.(pha|rsp)\", fname)\n",
    "#             if match:\n",
    "#                 expid, inst, ftype = match.groups()\n",
    "#                 full_path = os.path.join(root, fname)\n",
    "#                 exp_dict[expid][inst][ftype] = full_path\n",
    "#             elif re.match(r\"(.*?)_(LE|ME|HE)_specbkg\\.(pha|bak)\", fname):\n",
    "#                 match = re.match(r\"(.*?)_(LE|ME|HE)_specbkg\\.(pha|bak)\", fname)\n",
    "#                 expid, inst, ftype = match.groups()\n",
    "#                 full_path = os.path.join(root, fname)\n",
    "#                 exp_dict[expid][inst]['bak'] = full_path\n",
    "\n",
    "# # --- Generate .xcm ---\n",
    "# for expid, inst_data in exp_dict.items():\n",
    "#     spectrum_num = 1\n",
    "#     xspec_lines = [\n",
    "#         \"statistic chi\",\n",
    "#         \"cd ../\"\n",
    "#     ]\n",
    "#     missing_items = []\n",
    "\n",
    "#     for inst in ['LE', 'ME', 'HE']:\n",
    "#         files = inst_data[inst]\n",
    "#         if 'pha' not in files:\n",
    "#             missing_items.append(f\"{inst}.pha missing\")\n",
    "#             continue\n",
    "\n",
    "#         xspec_lines.append(f\"data {spectrum_num}:{spectrum_num} {files['pha']}\")\n",
    "\n",
    "#         if 'rsp' in files:\n",
    "#             xspec_lines.append(f\"response  1:{spectrum_num} {files['rsp']}\")\n",
    "#         else:\n",
    "#             missing_items.append(f\"{inst}.rsp missing\")\n",
    "\n",
    "#         if 'bak' in files:\n",
    "#             xspec_lines.append(f\"backgrnd {spectrum_num} {files['bak']}\")\n",
    "#         else:\n",
    "#             missing_items.append(f\"{inst}.bak missing\")\n",
    "\n",
    "#         spectrum_num += 1\n",
    "\n",
    "#     if missing_items:\n",
    "#         log_entries.append(f\"Skipped {expid}: \" + \"; \".join(missing_items))\n",
    "#         continue\n",
    "\n",
    "#     # Append the rest of the xspec options\n",
    "#     xspec_lines += [\n",
    "#         \"ignore 1:1-119,1053-1536 2:1-86,461-1024 3:1-5,25-256\",\n",
    "#         \"method leven 10 0.01\",\n",
    "#         \"abund wilm\",\n",
    "#         \"xsect vern\",\n",
    "#         \"cosmo 70 0 0.73\",\n",
    "#         \"xset delta 0.01\",\n",
    "#         \"systematic 0\",\n",
    "#         \"bayes off\"\n",
    "#     ]\n",
    "\n",
    "#     xcm_path = os.path.join(xcm_output_dir, f\"{expid}.xcm\")\n",
    "#     with open(xcm_path, 'w') as f:\n",
    "#         f.write(\"\\n\".join(xspec_lines))\n",
    "\n",
    "# # --- Write log ---\n",
    "# with open(log_path, 'w') as log_file:\n",
    "#     if log_entries:\n",
    "#         log_file.write(\"Skipped EXPOSURE_IDs with issues:\\n\")\n",
    "#         for entry in log_entries:\n",
    "#             log_file.write(entry + \"\\n\")\n",
    "#     else:\n",
    "#         log_file.write(\"All EXPOSURE_IDs processed successfully.\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "71c1df61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_exposure_files(base_dir):\n",
    "    exp_dict = defaultdict(lambda: {'LE': {}, 'ME': {}, 'HE': {}})\n",
    "\n",
    "    for root, dirs, files in os.walk(base_dir):\n",
    "        if \"pipeline_output\" in root:\n",
    "            for fname in files:\n",
    "                match = re.match(r\"(.*?)_(LE|ME|HE)_spec(?:_g0)?\\.(pha|rsp)\", fname)\n",
    "                if match:\n",
    "                    expid, inst, ftype = match.groups()\n",
    "                    full_path = os.path.join(root, fname)\n",
    "                    exp_dict[expid][inst][ftype] = full_path\n",
    "                elif re.match(r\"(.*?)_(LE|ME|HE)_specbkg\\.(pha|bak)\", fname):\n",
    "                    match = re.match(r\"(.*?)_(LE|ME|HE)_specbkg\\.(pha|bak)\", fname)\n",
    "                    expid, inst, ftype = match.groups()\n",
    "                    full_path = os.path.join(root, fname)\n",
    "                    exp_dict[expid][inst]['bak'] = full_path\n",
    "\n",
    "    return exp_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "60d98088",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_header_if_needed(pha_path, logger):\n",
    "    edited_path = pha_path.replace(\".pha\", \"_editedheader.pha\")\n",
    "    try:\n",
    "        with fits.open(pha_path) as hdul:\n",
    "            if hdul[1].header.get(\"HDUCLAS2\", \"\") == \"ALL\":\n",
    "                hdul[1].header[\"HDUCLAS2\"] = \"TOTAL\"\n",
    "                hdul.writeto(edited_path, overwrite=True)\n",
    "                logger.append(f\"Header fixed: {edited_path}\")\n",
    "            else:\n",
    "                edited_path = pha_path  # No need to change\n",
    "    except Exception as e:\n",
    "        logger.append(f\"Header fix failed for {pha_path}: {str(e)}\")\n",
    "        edited_path = None\n",
    "    return edited_path\n",
    "\n",
    "def run_ftgrouppha(infile,grouptype, groupscale,respfile, logger):\n",
    "    outfile = infile.replace(\"_editedheader.pha\", \"_grp_min.pha\")\n",
    "    cmd = [\n",
    "        \"ftgrouppha\",\n",
    "        f\"infile={infile}\",\n",
    "        f\"outfile={outfile}\",\n",
    "        f\"respfile={respfile}\",\n",
    "        f\"clobber=yes\",\n",
    "        f\"grouptype={grouptype}\",\n",
    "        f\"groupscale={groupscale}\"\n",
    "    ]\n",
    "\n",
    "    # cmd= [\"grppha\",\n",
    "    #       f\"{infile}\",\n",
    "    #       f\"{outfile}\",\n",
    "    #       f\"clobber=yes\",\n",
    "    #       f\"group {grouptype} {groupscale} & exit\"\n",
    "    # ]\n",
    "\n",
    "    try:\n",
    "        subprocess.run(cmd, check=True)\n",
    "        logger.append(f\"ftgrouppha success: {outfile}\")\n",
    "        return outfile\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        logger.append(f\"ftgrouppha failed: {infile} - {str(e)}\")\n",
    "        return None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4c3d8988",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_xcm(exp_dict, output_dir):\n",
    "    log_entries = []\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    for expid, inst_data in exp_dict.items():\n",
    "        xspec_lines = [\n",
    "            \"statistic chi\"\n",
    "        ]\n",
    "        spectrum_num = 1\n",
    "        missing_items = []\n",
    "\n",
    "        for inst in ['LE', 'ME', 'HE']:\n",
    "            files = inst_data[inst]\n",
    "            pha_file = files.get('pha')\n",
    "            rsp_file = files.get('rsp')\n",
    "            bak_file = files.get('bak')\n",
    "\n",
    "            if not pha_file or not os.path.exists(pha_file):\n",
    "                missing_items.append(f\"{inst}: no grouped PHA\")\n",
    "                continue\n",
    "\n",
    "            xspec_lines.append(f\"data {spectrum_num}:{spectrum_num} {pha_file}\")\n",
    "\n",
    "            if rsp_file:\n",
    "                xspec_lines.append(f\"response 1:{spectrum_num} {rsp_file}\")\n",
    "            else:\n",
    "                missing_items.append(f\"{inst}: missing RSP\")\n",
    "\n",
    "            if bak_file:\n",
    "                xspec_lines.append(f\"backgrnd {spectrum_num} {bak_file}\")\n",
    "            else:\n",
    "                missing_items.append(f\"{inst}: missing BAK\")\n",
    "\n",
    "            spectrum_num += 1\n",
    "\n",
    "        if missing_items:\n",
    "            log_entries.append(f\"Skipped {expid} due to missing files: {'; '.join(missing_items)}\")\n",
    "            continue\n",
    "\n",
    "        xspec_lines += [\n",
    "            \"ignore 1:**-2.0 9.0-** 2:**-8.0 28.0-** 3:**-28.0  50.0-**\",\n",
    "            \"method leven 10 0.01\",\n",
    "            \"abund wilm\",\n",
    "            \"xsect vern\",\n",
    "            \"cosmo 70 0 0.73\",\n",
    "            \"xset delta 0.01\",\n",
    "            \"systematic 0\",\n",
    "            \"bayes off\"\n",
    "        ]\n",
    "\n",
    "        xcm_path = os.path.join(output_dir, f\"{expid}_min.xcm\")\n",
    "        with open(xcm_path, 'w') as f:\n",
    "            f.write(\"\\n\".join(xspec_lines))\n",
    "\n",
    "        log_entries.append(f\"Wrote XCM for {expid}: {xcm_path}\")\n",
    "\n",
    "    return log_entries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "11a0ce3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    base_dir = \"/home/supremekai/thesis/J0243_6p6124/hxmt/hxmt_me_l3_products_pipeline\"\n",
    "    xcm_output_dir = \"/home/supremekai/thesis/J0243_6p6124/hxmt/hxmt_spec_results\"\n",
    "    log_path = os.path.join(xcm_output_dir, \"xcm_generation.log\")\n",
    "\n",
    "    groupscale=30\n",
    "    grouptype=\"min\" #other options are opt, optmin, smin\n",
    "\n",
    "    os.makedirs(xcm_output_dir, exist_ok=True)\n",
    "    log_entries = []\n",
    "\n",
    "    # Step 1: Collect all relevant files\n",
    "    exp_dict = collect_exposure_files(base_dir)\n",
    "\n",
    "    # Step 2: Fix headers and run ftgrouppha\n",
    "    for expid, inst_data in exp_dict.items():\n",
    "        for inst in ['LE', 'ME', 'HE']:\n",
    "            files = inst_data[inst]\n",
    "            if 'pha' not in files:\n",
    "                continue\n",
    "\n",
    "            original_pha = files['pha']\n",
    "            respfile=files['rsp']\n",
    "            edited_pha = fix_header_if_needed(original_pha, log_entries)\n",
    "            if not edited_pha:\n",
    "                continue\n",
    "            \n",
    "            if inst==\"LE\":\n",
    "                grouped_pha = run_ftgrouppha(edited_pha, grouptype, 100,respfile, log_entries)\n",
    "            else:\n",
    "                grouped_pha = run_ftgrouppha(edited_pha, grouptype, groupscale,respfile, log_entries)\n",
    "            if grouped_pha:\n",
    "                # Update exp_dict to point to grouped PHA\n",
    "                files['pha'] = grouped_pha\n",
    "\n",
    "    # Step 3: Generate XCM using updated paths\n",
    "    log_entries += generate_xcm(exp_dict, xcm_output_dir)\n",
    "\n",
    "    # Step 4: Write log\n",
    "    with open(log_path, 'w') as log_file:\n",
    "        if log_entries:\n",
    "            log_file.write(\"\\n\".join(log_entries))\n",
    "        else:\n",
    "            log_file.write(\"All EXPOSURE_IDs processed successfully.\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "heasoftenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
